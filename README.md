# nsfw_liveview
easy NSFW detection for Phoenix LiveView

Avoid nightmare of what people are uploading.

Just add an image and get parameters describing the image.
The library should categorize image probabilities in the following 5 classes:

- Drawing - safe for work drawings (including anime)
- Hentai - hentai and pornographic drawings
- Neutral - safe for work neutral images
- Porn - pornographic images, sexual acts
- Sexy - sexually explicit images, not pornography

Yet to decide about Training data and machine learning, tensorflow, etc.
